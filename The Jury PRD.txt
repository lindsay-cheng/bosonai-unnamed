Project Requirements Document: The Jury
High-Level Requirements (Revised)
1. Purpose & Vision
Goal: Create a voice-driven decision-making app where 3 AI personalities with distinct voices debate user questions and deliver verdicts.
Core Objective: Demonstrate BosonAI's voice cloning and TTS capabilities combined with LLM-generated responses for an entertaining, shareable experience.
Target Users:
* Hackathon judges evaluating creative API usage
* Gen Z/Millennial users seeking entertaining content
* Social media content creators
2. Key Features
Feature
	Description
	Priority
	Question input
	Text input for user questions (10-500 characters)
	Must
	LLM response generation
	Generate personality-driven responses using GPT/Claude
	Must
	Multi-voice deliberation
	3 jury members with cloned voices debate the question
	Must
	Audio synthesis
	Convert generated text to speech via BosonAI
	Must
	Sequential playback
	Play audio responses in order with visual feedback
	Must
	Verdict display
	Show final decision with reasoning
	Must
	Transcript export
	Download text version of deliberation
	Should
	3. System Architecture
User Input → LLM (text generation) → BosonAI (audio synthesis) → Sequential Playback


Flow:
1. User submits question
2. Backend generates 6 text responses (3 opening + 3 verdict) using LLM
3. Each response converted to audio via BosonAI voice cloning
4. Frontend plays audio sequentially with transcript display
5. Final verdict shown
4. Zodiac Jury Members (Demo: 3 of 12)
Name
	Archetype
	Voice Style
	Stance
	Dragon (龙)
	Bold visionary
	Confident, powerful, inspiring
	Optimistic (leans "yes")
	Ox (牛)
	Patient guardian
	Calm, methodical, firm
	Conservative (leans "no")
	Monkey (猴)
	Clever trickster
	Quick, playful, unpredictable
	Random

Note: Final product will feature all 12 zodiac animals with user selection of 3 per question.
	5. Technical Stack
Backend:
* Python 3.10+
* Flask for API
* OpenAI SDK (for both LLM and BosonAI)
* Optional: Anthropic SDK for Claude
Frontend:
* React 18+ with TypeScript
* Tailwind CSS
* Axios for HTTP
* HTML5 Audio API
APIs:
* BosonAI Higgs Audio (voice cloning + TTS)
* OpenAI GPT-4o-mini or Anthropic Claude Haiku (text generation)
6. Success Metrics
* End-to-end latency: Under 20 seconds
* Response quality: Contextual and personality-appropriate
* Audio quality: Clear, distinct voices
* Demo impact: Judges react positively within 30 seconds
* Technical completeness: Both LLM and voice cloning working
7. MVP Scope (24 Hours)
Must Have:
* Text input with validation
* LLM generates 6 contextual responses
* BosonAI synthesizes audio for all responses
* Sequential audio playback
* Verdict display
* Basic error handling
Won't Have:
* Voice input (ASR)
* User accounts
* Response caching
* Audio mixing/effects
* Custom jury selection
8. Constraints & Risks
Technical Constraints:
* BosonAI rate limits (unknown - test early)
* LLM token costs
* Browser audio compatibility
* CORS for frontend API calls
Risk Mitigation:
* Test APIs in first hour
* Fallback to template responses if LLM fails
* Fallback to text-only if BosonAI fails
* Implement comprehensive error handling
________________


Low-Level Requirements (Revised)
Backend Implementation
File Structure
backend/
├── voices/
│   ├── dragon.wav
│   ├── ox.wav
│   └── monkey.wav
├── temp/
├── jury_engine.py
├── app.py
├── requirements.txt
└── .env


Dependencies (requirements.txt)
openai==1.12.0
flask==3.0.0
flask-cors==4.0.0
python-dotenv==1.0.0
anthropic==0.18.0  # optional


Environment Variables (.env)
BOSON_API_KEY=your_boson_key
OPENAI_API_KEY=your_openai_key
LLM_PROVIDER=openai


Core Classes & Methods
JuryMember Class
class JuryMember:
    id: str                    # "dragon", "ox", "monkey"
    name: str                  # Display name
    emoji: str                 # Visual identifier (zodiac emoji)
    speaker_tag: str           # "[SPEAKER1]", "[SPEAKER2]", "[SPEAKER3]"
    ref_audio: str            # Path to reference audio
    ref_transcript: str       # Transcript with speaker tag
    personality_prompt: str   # System prompt for LLM
    stance: str               # "conservative", "optimistic", "chaotic"


JuryEngine Class
Constructor
def __init__(self, boson_api_key: str, llm_api_key: str, llm_provider: str = "openai"):
    # Initialize BosonAI client
    self.boson_client = OpenAI(
        api_key=boson_api_key,
        base_url="https://hackathon.boson.ai/v1"
    )
    
    # Initialize LLM client
    if llm_provider == "openai":
        self.llm_client = OpenAI(api_key=llm_api_key)
        self.llm_model = "gpt-4o-mini"
    
    # Define 3 jury members with personality prompts
    self.jury_members = [...]
    
    # BosonAI system prompt
    self.system_prompt = """You are an AI assistant designed to convert text into speech.
If the user's message includes a [SPEAKER*] tag, do not read out the tag and generate speech for the following text, using the specified voice.
If no speaker tag is present, select a suitable voice on your own.


<|scene_desc_start|>
Audio is recorded in a dramatic courtroom setting with slight reverb.
<|scene_desc_end|>"""


Text Generation Method
def generate_response(self, member: JuryMember, question: str, 
                     stage: str, verdict: str = None) -> str:
    """
    Generate personality-appropriate response using LLM
    
    Args:
        member: JuryMember with personality_prompt
        question: User's question
        stage: "opening" or "verdict"
        verdict: "yes", "no", or "maybe" (for verdict stage only)
    
    Returns:
        Generated text (20-40 words)
    
    Implementation:
        1. Build prompt based on stage
        2. For opening: ask for initial reaction
        3. For verdict: provide verdict and ask for reasoning
        4. Call LLM with personality_prompt as system message
        5. Use high temperature (0.9) for creativity
        6. Limit to 100 tokens
        7. Strip and return response
    """


Verdict Determination Method
def determine_verdict(self, question: str, member: JuryMember) -> str:
    """
    Determine verdict based on personality stance
    
    Returns: "yes", "no", or "maybe"
    
    Logic:
        - Conservative: 60% no, 25% maybe, 15% yes
        - Optimistic: 70% yes, 20% maybe, 10% no
        - Chaotic: 33% each
    """


Script Generation Method
def generate_script(self, question: str) -> (List[Dict], str):
    """
    Generate complete deliberation script using LLM
    
    Returns:
        (script, final_verdict)
        
    Process:
        1. Loop through jury members
        2. Generate opening response for each
        3. Determine individual verdict for each
        4. Generate verdict response with reasoning
        5. Calculate final verdict (majority rules)
        6. Return script array with {member, text, stage}
    """


Audio Synthesis Method
def synthesize_response(self, member: JuryMember, text: str, 
                       conversation_history: List = None) -> bytes:
    """
    Convert text to speech using BosonAI voice cloning
    
    Args:
        member: JuryMember with voice configuration
        text: Generated text to speak
        conversation_history: Previous messages for context
    
    Returns:
        Audio data as bytes (WAV format)
    
    Implementation:
        1. Build messages array:
           - System prompt with scene description
           - Reference transcript for speaker
           - Assistant message with input_audio (base64 encoded reference)
           - Conversation history (if provided)
           - Current request with speaker tag + text
        
        2. Call BosonAI API:
           model="higgs-audio-generation-Hackathon"
           modalities=["text", "audio"]
           max_completion_tokens=4096
           temperature=1.0
           top_p=0.95
           stop=["<|eot_id|>", "<|end_of_text|>", "<|audio_eos|>"]
           extra_body={"top_k": 50}
        
        3. Extract audio from response.choices[0].message.audio.data
        4. Base64 decode and return bytes
    """


Main Pipeline Method
def generate_deliberation(self, question: str) -> Dict:
    """
    Complete pipeline: text generation + audio synthesis
    
    Returns:
        {
            'question': str,
            'verdict': str,
            'script': List[{member, text, stage}],
            'audio_files': List[bytes]
        }
    
    Process:
        1. Generate script with LLM (6 responses)
        2. Initialize conversation_history
        3. For each script item:
           a. Call synthesize_response
           b. Append audio to audio_files
           c. Update conversation_history
           d. Handle errors gracefully (append None if failed)
        4. Return complete result dict
    """


Utility Method
def b64_encode(self, audio_path: str) -> str:
    """Base64 encode audio file"""


Personality Prompt Templates
Dragon (龙) System Prompt
You are Dragon, a bold and ambitious visionary from the Chinese zodiac.


Characteristics:
- Speak with confidence and inspiration
- Use powerful, motivating language
- See the potential in ideas
- Encourage bold action and innovation
- Default to "yes" with enthusiasm
- Natural leader energy


Example phrases: "Claim your destiny!", "Fortune favors the brave!", "This is your moment!"


When responding:
1. Acknowledge the question with confidence
2. Give an optimistic, empowering take
3. Inspire action (keep under 30 words)


Ox (牛) System Prompt
You are Ox, a patient and methodical guardian from the Chinese zodiac.


Characteristics:
- Speak calmly and deliberately
- Value tradition and proven methods
- Conservative and risk-averse
- Emphasize hard work and preparation
- Default to "no" unless well-justified
- Steady, reliable tone


Example phrases: "Slow and steady wins.", "Tradition guides us.", "Hard work first."


When responding:
1. Consider the question carefully
2. Express cautious perspective
3. Emphasize prudence (keep under 30 words)


Monkey (猴) System Prompt
You are Monkey, a clever and mischievous trickster from the Chinese zodiac.


Characteristics:
- Quick-witted and playful
- Embrace chaos and creativity
- Make unexpected connections
- Use clever wordplay
- Unpredictable verdicts
- Lighthearted but sharp


Example phrases: "Let's shake things up!", "Expect the unexpected!", "Rules? What rules?"


When responding:
1. React with playful cleverness
2. Give an unexpected angle
3. Be mischievously wise (keep under 30 words)


Flask API (app.py)
Endpoints
POST /api/verdict
Request: {"question": str}
Validation:
    - Length: 10-500 characters
    - Strip whitespace
    - Reject if empty


Process:
    1. Call engine.generate_deliberation(question)
    2. Generate unique verdict_id
    3. Save audio files to ./temp/{verdict_id}/{index}.wav
    4. Return response


Response: {
    "verdict_id": str,
    "question": str,
    "verdict": str,
    "deliberation": [{
        "speaker": {"id", "name", "emoji"},
        "text": str,
        "audio_index": int
    }]
}


Error codes:
    400: Invalid question
    500: Generation failed


GET /api/audio/{verdict_id}/{index}
Returns: WAV file from temp directory
Error: 404 if not found


GET /api/jury-members
Returns: {
    "members": [{
        "id": str,
        "name": str,
        "emoji": str,
        "stance": str
    }]
}


GET /health
Returns: {
    "status": "healthy",
    "bosonai": "connected",
    "llm": "connected"
}


Setup Requirements
* Enable CORS
* Create temp directory on startup
* Load environment variables
* Initialize JuryEngine with API keys
* Run on port 5000
Frontend Implementation
File Structure
frontend/
├── src/
│   ├── components/
│   │   ├── QuestionInput.tsx
│   │   ├── JuryPlayer.tsx
│   │   └── VerdictDisplay.tsx
│   ├── App.tsx
│   └── main.tsx
├── package.json
└── .env


Component Specifications
QuestionInput.tsx
Props:
    onSubmit: (question: string) => void
    isLoading: boolean


State:
    question: string
    charCount: number


Features:
    - Textarea input
    - Character counter (10-500)
    - Real-time validation
    - Submit button (disabled if invalid or loading)
    - Show loading spinner when isLoading=true


Styling:
    - Dark background
    - Gold/amber accent for submit button
    - Show error state if invalid


JuryPlayer.tsx
Props:
    deliberation: Array<{speaker, text, audio_index}>
    verdict_id: string
    apiUrl: string


State:
    currentIndex: number
    isPlaying: boolean
    audioRef: useRef<HTMLAudioElement>


Features:
    - Display all responses with speaker info
    - Highlight current speaker
    - Play/pause button
    - Auto-advance to next on audio end
    - Show loading if audio not ready
    - Handle audio errors gracefully


Audio playback:
    - Fetch audio from /api/audio/{verdict_id}/{index}
    - Use HTML5 Audio element
    - Sequential playback only
    - Update currentIndex on 'ended' event


Styling:
    - Card layout for each response
    - Emoji + name for each speaker
    - Pulse animation on active speaker
    - Transcript scrollable


VerdictDisplay.tsx
Props:
    verdict: "yes" | "no" | "maybe"


Features:
    - Large verdict badge
    - Color-coded:
        - Yes: green
        - No: red
        - Maybe: yellow
    - Animation on reveal


Styling:
    - Centered, prominent
    - Bold text
    - Gradient background based on verdict


App.tsx
State:
    question: string
    isLoading: boolean
    result: {verdict_id, question, verdict, deliberation} | null
    error: string | null
    stage: "input" | "loading" | "display"


Flow:
    1. Show QuestionInput (stage="input")
    2. On submit:
        a. Set isLoading=true, stage="loading"
        b. POST to /api/verdict
        c. On success: stage="display", show results
        d. On error: show error message, reset to input
    3. Show JuryPlayer + VerdictDisplay (stage="display")
    4. Provide "Ask Another" button to reset


Error handling:
    - Network errors
    - API errors
    - Audio playback errors
    - Display user-friendly messages


Performance & Optimization
Expected Latencies
* LLM text generation: 3-6 seconds (6 requests)
* BosonAI audio synthesis: 8-12 seconds (6 requests)
* Total end-to-end: 12-18 seconds
Optimization Strategies
1. Show progress indicator with stages
2. Consider parallel audio generation (max 3 concurrent)
3. Frontend starts playing first audio while others generate
4. Cache common questions (optional)
Error Handling Requirements
Backend Error Scenarios
* LLM API failure: Fall back to template responses
* BosonAI API failure: Continue with text-only mode
* Rate limit exceeded: Queue requests or return 429
* Invalid audio format: Log error, return null for that clip
* Network timeout: Retry with exponential backoff (max 2 retries)
Frontend Error Scenarios
* API unreachable: Show connection error
* Audio fails to load: Show text transcript only
* Playback error: Skip to next audio
* Timeout (>30s): Show timeout message with retry option
Testing Requirements
Backend Tests
* Verify LLM generates unique responses
* Confirm BosonAI uses correct speaker tags
* Test error handling for API failures
* Validate audio format (WAV)
* Check temp file cleanup
Integration Tests
* Full pipeline with sample question
* Verify all 6 audio files generated
* Confirm verdict logic works
* Test concurrent requests
Frontend Tests
* Input validation works
* Audio playback advances correctly
* Error states display properly
* Mobile responsive
Deployment Considerations
Backend
* Deploy to Railway/Render
* Set environment variables in dashboard
* Configure temp directory cleanup (delete after 1 hour)
* Add health check endpoint
* Enable request logging
Frontend
* Deploy to Vercel/Netlify
* Update API_URL to production backend
* Build with npm run build
* Configure CORS in backend for production domain
Cost Estimates (per deliberation)
* LLM (GPT-4o-mini): 6 requests × ~50 tokens = ~$0.001
* BosonAI: Unknown (check hackathon quota)
* Estimated total: $0.05-0.30 per question
Timeline (24 Hours)
Hours
	Task
	0-1
	Test both APIs, verify they work
	1-3
	Implement JuryEngine with LLM integration
	3-5
	Add BosonAI audio synthesis
	5-7
	Build Flask API with endpoints
	7-9
	Create React components
	9-11
	Integration and testing
	11-13
	UI polish and error handling
	13-14
	Demo prep and buffer time